# 实验5 神经网络实现（MLP vs CNN）

- 做了啥：搞了两套方案做 MNIST 识别。Part A 是手写（从零实现）一个多层感知机（MLP），自己推导反向传播和梯度下降；Part B 是用 PyTorch 搭了一个卷积神经网络（CNN）。最后对比了它俩的准确率、参数量和收敛速度。
- 遇到的问题：手写 MLP 的时候，反向传播的矩阵求导容易晕，维度经常对不上；MLP 把图片拉平（Flatten）后丢了空间结构信息，准确率卡在 92% 左右上不去；CNN 调参（卷积核大小、步长）比较繁琐。
- 解决方案：MLP 调试时多打印 shape，用简单的数值梯度检验（Gradient Check）验证推导；CNN 利用了卷积层的局部连接和权值共享，加上 MaxPool 降维，参数少效果好；用 PyTorch 这种框架，自动求导省了太多事，能专注于网络结构设计。
- 启发：处理图像，CNN 完爆 MLP，因为它尊重了图像的空间结构（平移不变性）；手写一次 BP 算法对理解“梯度是怎么传回来的”非常有帮助，但干活还是得用框架；参数少不代表模型弱，结构设计（Inductive Bias）比堆参数更重要。
